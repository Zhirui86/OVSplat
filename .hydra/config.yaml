dataset:
  view_sampler:
    name: bounded
    num_target_views: 1
    num_context_views: 2
    min_distance_between_context_views: 2
    max_distance_between_context_views: 6
    min_distance_to_context_views: 0
    warm_up_steps: 0
    initial_min_distance_between_context_views: 2
    initial_max_distance_between_context_views: 6
  name: scannet
  roots:
  - datasets/scannet
  make_baseline_1: false
  augment: true
  image_shape:
  - 256
  - 256
  background_color:
  - 0.0
  - 0.0
  - 0.0
  cameras_are_circular: false
  baseline_epsilon: 0.001
  max_fov: 100.0
  skip_bad_shape: true
  near: 1.0
  far: 100.0
  baseline_scale_bounds: false
  shuffle_val: true
  test_len: -1
  test_chunk_interval: 1
  overfit_to_scene: null
model:
  encoder:
    name: costvolume
    opacity_mapping:
      initial: 0.0
      final: 0.0
      warm_up: 1
    num_depth_candidates: 128
    num_surfaces: 1
    gaussians_per_pixel: 1
    gaussian_adapter:
      gaussian_scale_min: 0.5
      gaussian_scale_max: 15.0
      sh_degree: 4
    d_feature: 128
    visualizer:
      num_samples: 8
      min_resolution: 256
      export_ply: false
    unimatch_weights_path: null
    multiview_trans_attn_split: 2
    costvolume_unet_feat_dim: 128
    costvolume_unet_channel_mult:
    - 1
    - 1
    - 1
    costvolume_unet_attn_res:
    - 4
    depth_unet_feat_dim: 32
    depth_unet_attn_res:
    - 16
    depth_unet_channel_mult:
    - 1
    - 1
    - 1
    - 1
    - 1
    downscale_factor: 4
    shim_patch_size: 4
    wo_depth_refine: false
    wo_cost_volume: false
    wo_backbone_cross_attn: false
    wo_cost_volume_refine: false
    use_epipolar_trans: false
  semantic:
    name: semantic_generator
    backbone: clip_vitl16_384
    num_features: 256
    dropout: 0.1
    no_scaleinv: true
    no_batchnorm: false
    widehead: false
    widehead_hr: false
    arch_option: 1
    block_depth: 2
    activation: lrelu
    aux: false
    aux_weight: 0.2
    se_loss: false
    se_weight: 0.2
    ignore_index: 20
    use_bn: true
  autoencoder:
    name: autoencoder
    encoder_hidden_dims:
    - 256
    - 128
    - 64
    - 32
    decoder_hidden_dims:
    - 64
    - 128
    - 256
    - 256
    - 512
  decoder:
    name: splatting_cuda
loss:
  mse:
    weight: 1.0
  lpips:
    weight: 0.1
    apply_after_step: 0
wandb:
  project: ovsplat
  name: scannet
  mode: online
  id: null
  tags:
  - scannet
  - 256x256
mode: train
data_loader:
  train:
    num_workers: 10
    persistent_workers: true
    batch_size: 1
    seed: 1234
  test:
    num_workers: 4
    persistent_workers: false
    batch_size: 1
    seed: 2345
  val:
    num_workers: 1
    persistent_workers: true
    batch_size: 1
    seed: 3456
optimizer:
  lr: 1.5e-6
  warm_up_steps: 2000
  cosine_lr: True
checkpointing:
  load: /data/gyy/lsplat/checkpoints/view2step160000.ckpt
  every_n_train_steps: 10000
  save_top_k: -1
  pretrained_model: null
train:
  depth_mode: depth
  extended_visualization: false
  print_log_every_n_steps: 1
test:
  output_path: outputs/test
  compute_scores: true
  eval_time_skip_steps: 5
  save_image: true
  save_video: false
seed: 111123
trainer:
  max_steps: 300001
  val_check_interval: 0.5
  gradient_clip_val: 0.5
  num_sanity_val_steps: 2
output_dir: null
